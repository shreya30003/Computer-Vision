{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321376b5",
   "metadata": {},
   "source": [
    "Task 2: Image Segmentation for Medical Imaging:\n",
    "- Details : Develop a model for segmenting different regions of interest in medical images, such as tumors in MRI scans using conventional and deep models\n",
    "- Consider the  BraTS (Brain Tumor Segmentation) dataset. Apply basic image processing techniques for denoising and image enhancement and try to segment the tumor in the image using traditional segmentation approaches.\n",
    "- Use  appropriate U-Net architecture, which is specifically designed for medical image segmentation and try to calculate the performance metrics such as  Dice coefficient as the primary metric for evaluating segmentation performance.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/nurislamsowmik/3d-u-net-on-brats-2020\n",
    "https://github.com/ovh/ai-training-examples/blob/main/notebooks/computer-vision/image-segmentation/tensorflow/brain-tumor-segmentation-unet/notebook_image_segmentation_unet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b0851",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5260024",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:14.914581Z",
     "iopub.status.busy": "2023-12-04T20:20:14.913808Z",
     "iopub.status.idle": "2023-12-04T20:20:29.651081Z",
     "shell.execute_reply": "2023-12-04T20:20:29.650079Z"
    },
    "papermill": {
     "duration": 14.75267,
     "end_time": "2023-12-04T20:20:29.653452",
     "exception": false,
     "start_time": "2023-12-04T20:20:14.900782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.util import montage \n",
    "import skimage.transform as skTrans\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageOps  \n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021effd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:29.682012Z",
     "iopub.status.busy": "2023-12-04T20:20:29.681328Z",
     "iopub.status.idle": "2023-12-04T20:20:29.686816Z",
     "shell.execute_reply": "2023-12-04T20:20:29.685900Z"
    },
    "papermill": {
     "duration": 0.022723,
     "end_time": "2023-12-04T20:20:29.688761",
     "exception": false,
     "start_time": "2023-12-04T20:20:29.666038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DEFINE seg-areas  \n",
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
    "}\n",
    "\n",
    "# there are 155 slices per volume\n",
    "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
    "VOLUME_SLICES = 100 \n",
    "VOLUME_START_AT = 22 # first slice of volume that we will include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7f865",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:29.737659Z",
     "iopub.status.busy": "2023-12-04T20:20:29.737296Z",
     "iopub.status.idle": "2023-12-04T20:20:31.960393Z",
     "shell.execute_reply": "2023-12-04T20:20:31.959462Z"
    },
    "papermill": {
     "duration": 2.238912,
     "end_time": "2023-12-04T20:20:31.963338",
     "exception": false,
     "start_time": "2023-12-04T20:20:29.724426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "VALIDATION_DATASET_PATH = '../input/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "\n",
    "test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_flair.nii').get_fdata()\n",
    "test_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1.nii').get_fdata()\n",
    "test_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t1ce.nii').get_fdata()\n",
    "test_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_t2.nii').get_fdata()\n",
    "test_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_001/BraTS20_Training_001_seg.nii').get_fdata()\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\n",
    "slice_w = 25\n",
    "ax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax1.set_title('Image flair')\n",
    "ax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax2.set_title('Image t1')\n",
    "ax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax3.set_title('Image t1ce')\n",
    "ax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\n",
    "ax4.set_title('Image t2')\n",
    "ax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\n",
    "ax5.set_title('Mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfece89a",
   "metadata": {
    "papermill": {
     "duration": 0.07386,
     "end_time": "2023-12-04T20:20:46.338215",
     "exception": false,
     "start_time": "2023-12-04T20:20:46.264355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create model || U-Net: Convolutional Networks for Biomedical Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc4e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:46.459762Z",
     "iopub.status.busy": "2023-12-04T20:20:46.459064Z",
     "iopub.status.idle": "2023-12-04T20:20:46.475821Z",
     "shell.execute_reply": "2023-12-04T20:20:46.474965Z"
    },
    "papermill": {
     "duration": 0.049905,
     "end_time": "2023-12-04T20:20:46.477768",
     "exception": false,
     "start_time": "2023-12-04T20:20:46.427863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dice loss as defined above for 4 classes\n",
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_true_f = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_f = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
    "   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "#    K.print_tensor(total_loss, message=' total dice coef: ')\n",
    "    return total_loss\n",
    "\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64978697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:46.540567Z",
     "iopub.status.busy": "2023-12-04T20:20:46.539875Z",
     "iopub.status.idle": "2023-12-04T20:20:46.543993Z",
     "shell.execute_reply": "2023-12-04T20:20:46.543162Z"
    },
    "papermill": {
     "duration": 0.038292,
     "end_time": "2023-12-04T20:20:46.545897",
     "exception": false,
     "start_time": "2023-12-04T20:20:46.507605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46b15b",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:46.605923Z",
     "iopub.status.busy": "2023-12-04T20:20:46.605646Z",
     "iopub.status.idle": "2023-12-04T20:20:49.909589Z",
     "shell.execute_reply": "2023-12-04T20:20:49.908793Z"
    },
    "papermill": {
     "duration": 3.336659,
     "end_time": "2023-12-04T20:20:49.911833",
     "exception": false,
     "start_time": "2023-12-04T20:20:46.575174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_unet(inputs, ker_init, dropout):\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04c09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:50.032966Z",
     "iopub.status.busy": "2023-12-04T20:20:50.032590Z",
     "iopub.status.idle": "2023-12-04T20:20:50.467618Z",
     "shell.execute_reply": "2023-12-04T20:20:50.466738Z"
    },
    "papermill": {
     "duration": 0.472313,
     "end_time": "2023-12-04T20:20:50.474063",
     "exception": false,
     "start_time": "2023-12-04T20:20:50.001750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_model(model, \n",
    "           show_shapes = True,\n",
    "           show_dtype=False,\n",
    "           show_layer_names = True, \n",
    "           rankdir = 'TB', \n",
    "           expand_nested = False, \n",
    "           dpi = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71a0c7",
   "metadata": {
    "papermill": {
     "duration": 0.036475,
     "end_time": "2023-12-04T20:20:50.549734",
     "exception": false,
     "start_time": "2023-12-04T20:20:50.513259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c8501e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:50.623567Z",
     "iopub.status.busy": "2023-12-04T20:20:50.622926Z",
     "iopub.status.idle": "2023-12-04T20:20:50.680614Z",
     "shell.execute_reply": "2023-12-04T20:20:50.679715Z"
    },
    "papermill": {
     "duration": 0.097101,
     "end_time": "2023-12-04T20:20:50.682773",
     "exception": false,
     "start_time": "2023-12-04T20:20:50.585672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n",
    "\n",
    "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
    "train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n",
    "\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories); \n",
    "\n",
    "    \n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c39606",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:50.829247Z",
     "iopub.status.busy": "2023-12-04T20:20:50.828875Z",
     "iopub.status.idle": "2023-12-04T20:20:50.844830Z",
     "shell.execute_reply": "2023-12-04T20:20:50.844094Z"
    },
    "papermill": {
     "duration": 0.054742,
     "end_time": "2023-12-04T20:20:50.846816",
     "exception": false,
     "start_time": "2023-12-04T20:20:50.792074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "                    \n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586de073",
   "metadata": {
    "papermill": {
     "duration": 0.040957,
     "end_time": "2023-12-04T20:20:51.308199",
     "exception": false,
     "start_time": "2023-12-04T20:20:51.267242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`Add callback for training process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55ecc0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:51.385569Z",
     "iopub.status.busy": "2023-12-04T20:20:51.385176Z",
     "iopub.status.idle": "2023-12-04T20:20:51.390738Z",
     "shell.execute_reply": "2023-12-04T20:20:51.389832Z"
    },
    "papermill": {
     "duration": 0.046644,
     "end_time": "2023-12-04T20:20:51.392818",
     "exception": false,
     "start_time": "2023-12-04T20:20:51.346174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
    "#                               patience=2, verbose=1, mode='auto'),\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1),\n",
    "#  keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
    "#                             verbose=1, save_best_only=True, save_weights_only = True)\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313d659c",
   "metadata": {
    "papermill": {
     "duration": 0.036627,
     "end_time": "2023-12-04T20:20:51.465915",
     "exception": false,
     "start_time": "2023-12-04T20:20:51.429288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbe8d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:51.543042Z",
     "iopub.status.busy": "2023-12-04T20:20:51.542668Z",
     "iopub.status.idle": "2023-12-04T20:20:51.547007Z",
     "shell.execute_reply": "2023-12-04T20:20:51.546188Z"
    },
    "papermill": {
     "duration": 0.045361,
     "end_time": "2023-12-04T20:20:51.548969",
     "exception": false,
     "start_time": "2023-12-04T20:20:51.503608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                     epochs=35,\n",
    "                     steps_per_epoch=len(train_ids),\n",
    "                     callbacks= callbacks,\n",
    "                     validation_data = valid_generator\n",
    "                     )  \n",
    "model.save(\"model_x1_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734fed8",
   "metadata": {
    "papermill": {
     "duration": 0.0358,
     "end_time": "2023-12-04T20:20:51.620935",
     "exception": false,
     "start_time": "2023-12-04T20:20:51.585135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`Visualize the training process`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25a332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:51.694070Z",
     "iopub.status.busy": "2023-12-04T20:20:51.693696Z",
     "iopub.status.idle": "2023-12-04T20:20:53.434530Z",
     "shell.execute_reply": "2023-12-04T20:20:53.433653Z"
    },
    "papermill": {
     "duration": 1.781698,
     "end_time": "2023-12-04T20:20:53.438324",
     "exception": false,
     "start_time": "2023-12-04T20:20:51.656626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model = keras.models.load_model('../input/modelperclasseval/model_per_class.h5', \n",
    "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                                                   \"dice_coef\": dice_coef,\n",
    "                                                   \"precision\": precision,\n",
    "                                                   \"sensitivity\":sensitivity,\n",
    "                                                   \"specificity\":specificity,\n",
    "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
    "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
    "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
    "                                                  }, compile=False)\n",
    "\n",
    "history = pd.read_csv('../input/modelperclasseval/training_per_class.log', sep=',', engine='python')\n",
    "\n",
    "hist = history\n",
    "# hist = history.history\n",
    "acc=hist['accuracy']\n",
    "val_acc=hist['val_accuracy']\n",
    "\n",
    "epoch=range(len(acc))\n",
    "\n",
    "loss=hist['loss']\n",
    "val_loss=hist['val_loss']\n",
    "\n",
    "train_dice=hist['dice_coef']\n",
    "val_dice=hist['val_dice_coef']\n",
    "\n",
    "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
    "\n",
    "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
    "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
    "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
    "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
    "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb2319",
   "metadata": {
    "papermill": {
     "duration": 0.037993,
     "end_time": "2023-12-04T20:20:53.519440",
     "exception": false,
     "start_time": "2023-12-04T20:20:53.481447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02a261",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:53.599576Z",
     "iopub.status.busy": "2023-12-04T20:20:53.598471Z",
     "iopub.status.idle": "2023-12-04T20:20:53.613854Z",
     "shell.execute_reply": "2023-12-04T20:20:53.612999Z"
    },
    "papermill": {
     "duration": 0.057687,
     "end_time": "2023-12-04T20:20:53.615849",
     "exception": false,
     "start_time": "2023-12-04T20:20:53.558162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imageLoader(path):\n",
    "    image = nib.load(path).get_fdata()\n",
    "    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "    return np.array(image)\n",
    "\n",
    "def loadDataFromDir(path, list_of_files, mriType, n_images):\n",
    "    scans = []\n",
    "    masks = []\n",
    "    for i in list_of_files[:n_images]:\n",
    "        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n",
    "        currentScanVolume = imageLoader(fullPath)\n",
    "        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n",
    "        # for each slice in 3D volume, find also it's mask\n",
    "        for j in range(0, currentScanVolume.shape[2]):\n",
    "            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n",
    "            scans.append(scan_img[..., np.newaxis])\n",
    "            masks.append(mask_img[..., np.newaxis])\n",
    "    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n",
    "        \n",
    "#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfab4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T20:20:53.693454Z",
     "iopub.status.busy": "2023-12-04T20:20:53.693141Z",
     "iopub.status.idle": "2023-12-04T20:21:13.202421Z",
     "shell.execute_reply": "2023-12-04T20:21:13.201519Z"
    },
    "papermill": {
     "duration": 19.55157,
     "end_time": "2023-12-04T20:21:13.205086",
     "exception": false,
     "start_time": "2023-12-04T20:20:53.653516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predictByPath(case_path,case):\n",
    "    files = next(os.walk(case_path))[2]\n",
    "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
    "  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n",
    "    flair=nib.load(vol_path).get_fdata()\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n",
    "    ce=nib.load(vol_path).get_fdata() \n",
    "    \n",
    " #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n",
    " #   seg=nib.load(vol_path).get_fdata()  \n",
    "\n",
    "    \n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    " #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n",
    "    return model.predict(X/np.max(X), verbose=1)\n",
    "\n",
    "\n",
    "def showPredictsById(case, start_slice = 60):\n",
    "    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "    p = predictByPath(path,case)\n",
    "\n",
    "    core = p[:,:,:,1]\n",
    "    edema= p[:,:,:,2]\n",
    "    enhancing = p[:,:,:,3]\n",
    "\n",
    "    plt.figure(figsize=(18, 50))\n",
    "    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n",
    "\n",
    "    for i in range(6): # for each image, add brain background\n",
    "        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
    "    \n",
    "    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
    "    axarr[0].title.set_text('Original image flair')\n",
    "    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
    "    axarr[1].title.set_text('Ground truth')\n",
    "    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
    "    axarr[2].title.set_text('all classes')\n",
    "    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
    "    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
    "    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "showPredictsById(case=test_ids[0][-3:])\n",
    "showPredictsById(case=test_ids[1][-3:])\n",
    "showPredictsById(case=test_ids[2][-3:])\n",
    "showPredictsById(case=test_ids[3][-3:])\n",
    "showPredictsById(case=test_ids[4][-3:])\n",
    "showPredictsById(case=test_ids[5][-3:])\n",
    "showPredictsById(case=test_ids[6][-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9acf34",
   "metadata": {
    "papermill": {
     "duration": 0.049119,
     "end_time": "2023-12-04T20:21:13.306349",
     "exception": false,
     "start_time": "2023-12-04T20:21:13.257230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f4cf7",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-12-04T20:21:14.203408Z",
     "iopub.status.busy": "2023-12-04T20:21:14.202668Z",
     "iopub.status.idle": "2023-12-04T20:21:51.282212Z",
     "shell.execute_reply": "2023-12-04T20:21:51.281304Z"
    },
    "papermill": {
     "duration": 37.133192,
     "end_time": "2023-12-04T20:21:51.284203",
     "exception": false,
     "start_time": "2023-12-04T20:21:14.151011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154abb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 751906,
     "sourceId": 1299795,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1221832,
     "sourceId": 2039896,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1252728,
     "sourceId": 2089321,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 139.616105,
   "end_time": "2023-12-04T20:21:54.937951",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-04T20:19:35.321846",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
